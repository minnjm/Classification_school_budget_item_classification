{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Label line-item in a school budget\n",
    "How to accurately classify line-items in a school budget based on what that money is being used for?<br>\n",
    "There are 9 columns of labels, each will be converted to categorical variable, so it is 9 one-vs-all classifications.<br>\n",
    "There are two numeric features and fourteen free form text columns.<br>\n",
    "The free form text columns are converted to tens of thousands features using tokenization, bag of words and n-gram NLP techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400277, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# read training dataset\n",
    "df = pd.read_csv('TrainingData.csv', index_col=0)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take. The compitition web site list all the labels column names under \"Label example\" section. So populate LABELS list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['Function', 'Object_Type', 'Operating_Status', 'Position_Type', 'Pre_K', 'Reporting', 'Sharing', 'Student_Type', 'Use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', \"Total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the columns of labels to categorical class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Object_Type         category\n",
      "Operating_Status    category\n",
      "Position_Type       category\n",
      "Pre_K               category\n",
      "Reporting           category\n",
      "Sharing             category\n",
      "Student_Type        category\n",
      "Use                 category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always create a small size subset of df for testing. The subset and training and test sets should include samples covered all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production run\n"
     ]
    }
   ],
   "source": [
    "from multilabel import multilabel_sample_dataframe, multilabel_train_test_split\n",
    "\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# flag for production (submission)\n",
    "f_prod = 1\n",
    "\n",
    "if f_prod:\n",
    "    print('production run')\n",
    "    dummy_labels = pd.get_dummies(df[LABELS])\n",
    "    \n",
    "    #X_train=df[NON_LABELS]\n",
    "    #y_train=dummy_labels\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2,\n",
    "                                                               min_count=3,\n",
    "                                                               seed=43)\n",
    "    \n",
    "    #print(X_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    \n",
    "else:\n",
    "    print('pre-production run')\n",
    "    SAMPLE_SIZE = 40000\n",
    "    \n",
    "    df_samples = multilabel_sample_dataframe(df,\n",
    "                                       pd.get_dummies(df[LABELS]),\n",
    "                                       size=SAMPLE_SIZE,\n",
    "                                       min_count=25,\n",
    "                                       seed=34)\n",
    "    \n",
    "    dummy_labels = pd.get_dummies(df_samples[LABELS])\n",
    "                                             \n",
    "    X_train, X_test, y_train, y_test = multilabel_train_test_split(df_samples[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2,\n",
    "                                                               min_count=3,\n",
    "                                                               seed=43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dummy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\" Computes the logarithmic loss between predicted and\n",
    "    actual when these are 1D arrays.\n",
    "    :param predicted: The predicted probabilities as floats between 0-1\n",
    "    :param actual: The actual binary labels. Either 0 or 1.\n",
    "    :param eps (optional): log(0) is inf, so we need to offset our\n",
    "    predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "            + (1 - actual)\n",
    "            * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" Takes the dataset as read in, drops the non-feature, non-text columns and\n",
    "        then combines all of the text columns into a single vector that has all of\n",
    "        the text for a row.\n",
    "        \n",
    "        :param data_frame: The data as read in with read_csv (no preprocessing necessary)\n",
    "        :param to_drop (optional): Removes the numeric and label columns by default.\n",
    "    \"\"\"\n",
    "    # drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # joins all of the text items in a row (axis=1)\n",
    "    # with a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert python functions to 'model', class so it can be used as model\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13     Personal Services - Secretaries   SECRETARY  L...\n",
       "200    Personal Services - Other Compensation     Off...\n",
       "375    EMPLOYEE BENEFITS STUDENT SERVICES CHARTER SCH...\n",
       "533    SALARIES OF REGULAR EMPLOYEES MAINTENANCE  MIL...\n",
       "610    Telephone Service  Community Services    Commu...\n",
       "dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_data.fit_transform(df_samples.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21128.632098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1166.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>143.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1627.942960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FTE         Total\n",
       "13   1.0  21128.632098\n",
       "200  0.0   1166.790000\n",
       "375  NaN    143.840000\n",
       "533  NaN   1627.942960\n",
       "610  NaN      3.660000"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numeric_data.fit_transform(df_samples.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from SparseInteractions import SparseInteractions\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "input_d = chi_k * (chi_k - 1)\n",
    "layer1_nodes=chi_k**2\n",
    "output_nodes=dummy_labels.shape[1]\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_nodes, input_shape=(1128753,), activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2)))\n",
    "#                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "#                                                      non_negative=True, norm=None, binary=False,\n",
    "#                                                     ngram_range=(1, 2))),\n",
    "#                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "#        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "#        ('clf', OneVsRestClassifier(SGDClassifier(loss='log', penalty='elasticnet', alpha=0.0001, random_state=22)))\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "#        ('clf', KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=400, verbose=0))\n",
    "    ])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "parameters = {'clf__estimator__loss': ['log'],\n",
    "             'clf__estimator__alpha': [0.001, 0.0001, 0.00001],\n",
    "           'clf__estimator__penalty': ['elasticnet']}\n",
    "\n",
    "# Instantiate the GridSearchCV object: pl_cv\n",
    "pl_cv = GridSearchCV(pl, param_grid=parameters, cv=5)\n",
    "\n",
    "pl_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(pl_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(pl_cv.best_score_))\n",
    "\"\"\"\n",
    "\n",
    "#pl.fit_transform(X_train, y_train)\n",
    "pl.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320222, 16)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-production run\n",
      "\n",
      "Accuracy on data - test data:  0.920067453626\n",
      "\n",
      "log_loss on test data:  20.3658167409\n"
     ]
    }
   ],
   "source": [
    "#if f_prod:\n",
    "if 1:\n",
    "    print('pre-production run')\n",
    "    \n",
    "    # Compute and print accuracy\n",
    "    accuracy = pl.score(X_test, y_test)\n",
    "    print(\"\\nAccuracy on data - test data: \", accuracy)\n",
    "\n",
    "    # compute log loss instead\n",
    "    predictionsCV = pl.predict_proba(X_test)\n",
    "    \n",
    "    #print(predictionsCV.)\n",
    "\n",
    "\n",
    "\n",
    "    predictionCV_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],prefix_sep='_').columns,\n",
    "                             index=X_test.index,\n",
    "                             data=predictionsCV)\n",
    "\n",
    "    ll = log_loss(y_test, predictionCV_df)\n",
    "\n",
    "    print(\"\\nlog_loss on test data: \", ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Student_Type_Special Education</th>\n",
       "      <th>Student_Type_Unspecified</th>\n",
       "      <th>Use_Business Services</th>\n",
       "      <th>Use_ISPD</th>\n",
       "      <th>Use_Instruction</th>\n",
       "      <th>Use_Leadership</th>\n",
       "      <th>Use_NO_LABEL</th>\n",
       "      <th>Use_O&amp;M</th>\n",
       "      <th>Use_Pupil Services &amp; Enrichment</th>\n",
       "      <th>Use_Untracked Budget Set-Aside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>5.628961e-05</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126378</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>4.448786e-05</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.656508</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18698</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.472766e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.996658</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169914</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>3.486713e-05</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.993098</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.994863</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43727</th>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>6.676766e-03</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>0.951176</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.063056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "206341                     0.000179                               0.000286   \n",
       "126378                     0.000073                               0.000038   \n",
       "18698                      0.000010                               0.000010   \n",
       "169914                     0.000077                               0.000270   \n",
       "43727                      0.000106                               0.000057   \n",
       "\n",
       "        Function_Communications  Function_Curriculum Development  \\\n",
       "206341                 0.000092                     5.628961e-05   \n",
       "126378                 0.000052                     4.448786e-05   \n",
       "18698                  0.000010                     9.472766e-07   \n",
       "169914                 0.000840                     3.486713e-05   \n",
       "43727                  0.000100                     6.676766e-03   \n",
       "\n",
       "        Function_Data Processing & Information Services  \\\n",
       "206341                                         0.000224   \n",
       "126378                                         0.000104   \n",
       "18698                                          0.000015   \n",
       "169914                                         0.000061   \n",
       "43727                                          0.000174   \n",
       "\n",
       "        Function_Development & Fundraising  Function_Enrichment  \\\n",
       "206341                            0.000073             0.000189   \n",
       "126378                            0.000020             0.001135   \n",
       "18698                             0.000004             0.000003   \n",
       "169914                            0.000747             0.000125   \n",
       "43727                             0.000022             0.001222   \n",
       "\n",
       "        Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "206341                           0.000027                           0.000002   \n",
       "126378                           0.000025                           0.002636   \n",
       "18698                            0.000043                           0.000034   \n",
       "169914                           0.000096                           0.017872   \n",
       "43727                            0.000048                           0.000122   \n",
       "\n",
       "        Function_Facilities Planning               ...                \\\n",
       "206341                      0.000066               ...                 \n",
       "126378                      0.000016               ...                 \n",
       "18698                       0.000003               ...                 \n",
       "169914                      0.000069               ...                 \n",
       "43727                       0.000031               ...                 \n",
       "\n",
       "        Student_Type_Special Education  Student_Type_Unspecified  \\\n",
       "206341                        0.000096                  0.000005   \n",
       "126378                        0.000062                  0.999220   \n",
       "18698                         0.000590                  0.996658   \n",
       "169914                        0.000309                  0.993098   \n",
       "43727                         0.000108                  0.036362   \n",
       "\n",
       "        Use_Business Services  Use_ISPD  Use_Instruction  Use_Leadership  \\\n",
       "206341               0.000257  0.000066         0.000046        0.000001   \n",
       "126378               0.000301  0.000113         0.656508        0.001842   \n",
       "18698                0.000007  0.000029         0.999914        0.000004   \n",
       "169914               0.001401  0.000169         0.000007        0.002416   \n",
       "43727                0.000540  0.016078         0.000424        0.012615   \n",
       "\n",
       "        Use_NO_LABEL   Use_O&M  Use_Pupil Services & Enrichment  \\\n",
       "206341      0.999997  0.000018                         0.000254   \n",
       "126378      0.016257  0.033548                         0.001633   \n",
       "18698       0.000319  0.000021                         0.000002   \n",
       "169914      0.015353  0.994863                         0.001797   \n",
       "43727       0.951176  0.000195                         0.002471   \n",
       "\n",
       "        Use_Untracked Budget Set-Aside  \n",
       "206341                        0.000087  \n",
       "126378                        0.000042  \n",
       "18698                         0.000001  \n",
       "169914                        0.000108  \n",
       "43727                         0.063056  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionCV_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80055, 104)\n"
     ]
    }
   ],
   "source": [
    "print(predictionsCV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make prediction and export to predictions.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production run\n",
      "(50064, 104)\n"
     ]
    }
   ],
   "source": [
    "if f_prod:\n",
    "    print('production run')\n",
    "    # Load the holdout data: holdout\n",
    "    holdout = pd.read_csv('HoldoutData.csv', index_col=0, low_memory=False)\n",
    "\n",
    "    predictions = pl.predict_proba(holdout)\n",
    "\n",
    "    # Format predictions in DataFrame: prediction_df\n",
    "    prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "    prediction_df.to_csv('predictions.csv')\n",
    "\n",
    "    print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28322)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following will return (1, n_features)\n",
    "pl.get_params()['clf'].estimators_[0].coef_.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
